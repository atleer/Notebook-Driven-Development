{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590edc4e-528a-4894-a57f-e453414dd7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install papermill pandas hvplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a09b36f-1c95-4736-a574-bc1270c9718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a3850d-f649-49dd-9b93-820b6ddb76b4",
   "metadata": {},
   "source": [
    "# Parameterization of Notebooks\n",
    "\n",
    "Parameterizing Jupyter notebooks means making them flexible so you can easily change input values, like datasets, without having to edit the code each time. \n",
    "This is helpful when you need to run the same analysis or process with different data. \n",
    "It saves time and avoids mistakes because you don’t have to rewrite anything. \n",
    "Instead, you can just set the new inputs and run the notebook again for different tasks or data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eea061-652d-42db-8b3e-f11678c2db05",
   "metadata": {},
   "source": [
    "## Passing in Parameters To Notebooks With Papermill\n",
    "\n",
    "Papermill helps with parameterizing Jupyter notebooks by allowing us to inject new inputs (parameters) into a notebook before running it. \n",
    "Parameters have placeholders in the template notebook, and when we run Papermill, it fills those placeholders with the actual values we provide. \n",
    "Papermill then executes the entire notebook with the new inputs, saving the results in a new output notebook. \n",
    "This makes it easy to reuse the same notebook for different data or settings, automating tasks like batch processing, reporting, or experimentation with different variables.\n",
    "\n",
    "For this example we will use two notebooks: `notebook_1.ipynb` (access data from a remote url and prepares a processed csv file) and `notebook_2.ipynb` (needs processed csv for analysis)\n",
    "\n",
    "Run the below code to access notebooks. Feel free to go through the notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8905a80e-3db1-46a0-a4e6-ab25ec79e6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading parameterization/notebook_1.ipynb: 100%|██████████████████████████████████████| 4.92k/4.92k [00:00<?, ?B/s]\n",
      "Downloading parameterization/notebook_2.ipynb: 100%|██████████████████████████████████████| 2.05k/2.05k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('src')\n",
    "import sciebo\n",
    "\n",
    "sciebo.download_file('https://uni-bonn.sciebo.de/s/bHyVzeE8yGAzD5S', 'parameterization/notebook_1.ipynb')\n",
    "sciebo.download_file('https://uni-bonn.sciebo.de/s/xS6Skp6IOO0DhDI', 'parameterization/notebook_2.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54950fb2-794d-4005-b446-3b05ece867f8",
   "metadata": {},
   "source": [
    "**Example** In `notebook_1.ipynb`, tag the cell containing the below variables as `parameters`. \n",
    "\n",
    "| **Parameter**   | **Description**                   | **Type**  |\n",
    "|-----------------|-----------------------------------|-----------|\n",
    "| `input_csv_url`     | url of input CSV file        | String    |\n",
    "| `output_csv`    | Path to save the processed CSV    | String    |\n",
    "| `num_rows_display`    | Number of rows to display    | Integer    |\n",
    "\n",
    "To make papermill know that a cell contains parameters\n",
    "\n",
    "1. Put all parameters in a single cell before any other cell that uses them\n",
    "2. Click on the cell and then the gear icon next to the notebook\n",
    "3. Type `parameters` within Cell Tags\n",
    "\n",
    "It has been done for `notebook_1.ipynb`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22960974-531e-4582-90fa-3bf06f0cdc5a",
   "metadata": {},
   "source": [
    "In `notebook_2.ipynb`, tag the cell containing the below variables as `parameters`.\n",
    "\n",
    "| **Parameter**      | **Description**                   | **Type**  |\n",
    "|--------------------|-----------------------------------|-----------|\n",
    "| `processed_csv`    | Path to the processed CSV file    | String    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337cf8ce-f930-4465-967d-6513084e3d4c",
   "metadata": {},
   "source": [
    "**Example** Run `notebook_1.csv` specifying that the output should be called `processed_run_1.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e89fedb5-a479-4b80-87a6-efa2a52676ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sangeetha\\anaconda3\\envs\\ndd\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Executing: 100%|█████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.33cell/s]\n"
     ]
    }
   ],
   "source": [
    "params = dict(output_csv = \"processed_run_1.csv\")\n",
    "pm.execute_notebook(\n",
    "    'parameterization/notebook_1.ipynb',\n",
    "    'output_notebook_run_1.ipynb',\n",
    "    parameters = params\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3567134-514a-4502-a2fe-6b83e077a026",
   "metadata": {},
   "source": [
    "When you open output_notebook_run_1.ipynb, you will see that it is the same as the input notebook with an addition of one more cell with our injected parameters right beneath the cell tagged as parameters.\n",
    "\n",
    "Run `notebook_1.ipynb` specifying that the output should be called `processed_run_2.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cfec4ca-0337-44c1-b33e-5ac69a23b440",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|█████████████████████████████████████████████████████████████████████| 12/12 [00:03<00:00,  3.53cell/s]\n"
     ]
    }
   ],
   "source": [
    "params = dict(output_csv = \"processed_run_2.csv\")\n",
    "pm.execute_notebook(\n",
    "    'parameterization/notebook_1.ipynb',\n",
    "    'output_notebook_run_2.ipynb',\n",
    "    parameters = params\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fbad04-2c60-4522-8e42-44ae7eb901fb",
   "metadata": {},
   "source": [
    "Let's assume that we have a new dataset stored remotely in `url=\"https://uni-bonn.sciebo.de/s/W7BDPZefE53j7sy/download\"`. \n",
    "We want to process that data the same way with `notebook_1.ipynb`.\n",
    "\n",
    "Run `notebook_1.ipynb` specifying the remote source is now in `https://uni-bonn.sciebo.de/s/W7BDPZefE53j7sy/download`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e3b49c-b28c-4e96-b4ae-4b6b722af0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing:  50%|███████████████████████████████████                                   | 6/12 [00:04<00:04,  1.42cell/s]\n"
     ]
    },
    {
     "ename": "PapermillExecutionError",
     "evalue": "\n---------------------------------------------------------------------------\nException encountered at \"In [4]\":\n---------------------------------------------------------------------------\nUnicodeDecodeError                        Traceback (most recent call last)\nCell In[4], line 1\n----> 1 df = pd.read_csv(input_csv_url)\n\nFile c:\\Users\\sangeetha\\anaconda3\\envs\\ndd\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-> 1026 return _read(filepath_or_buffer, kwds)\n\nFile c:\\Users\\sangeetha\\anaconda3\\envs\\ndd\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--> 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile c:\\Users\\sangeetha\\anaconda3\\envs\\ndd\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-> 1620 self._engine = self._make_engine(f, self.engine)\n\nFile c:\\Users\\sangeetha\\anaconda3\\envs\\ndd\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898, in TextFileReader._make_engine(self, f, engine)\n   1895     raise ValueError(msg)\n   1897 try:\n-> 1898     return mapping[engine](f, **self.options)\n   1899 except Exception:\n   1900     if self.handles is not None:\n\nFile c:\\Users\\sangeetha\\anaconda3\\envs\\ndd\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93, in CParserWrapper.__init__(self, src, **kwds)\n     90 if kwds[\"dtype_backend\"] == \"pyarrow\":\n     91     # Fail here loudly instead of in cython after reading\n     92     import_optional_dependency(\"pyarrow\")\n---> 93 self._reader = parsers.TextReader(src, **kwds)\n     95 self.unnamed_cols = self._reader.unnamed_cols\n     97 # error: Cannot determine type of 'names'\n\nFile parsers.pyx:574, in pandas._libs.parsers.TextReader.__cinit__()\n\nFile parsers.pyx:663, in pandas._libs.parsers.TextReader._get_header()\n\nFile parsers.pyx:874, in pandas._libs.parsers.TextReader._tokenize_rows()\n\nFile parsers.pyx:891, in pandas._libs.parsers.TextReader._check_tokenize_status()\n\nFile parsers.pyx:2053, in pandas._libs.parsers.raise_parser_error()\n\nFile <frozen codecs>:322, in decode(self, input, final)\n\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x96 in position 22: invalid start byte\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPapermillExecutionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(input_csv_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://uni-bonn.sciebo.de/s/Y1JeD24HfskD2Qd/download\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_notebook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparameterization/notebook_1.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparameterization/output_notebook_run_3.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m;\n",
      "File \u001b[1;32mc:\\Users\\sangeetha\\anaconda3\\envs\\ndd\\Lib\\site-packages\\papermill\\execute.py:131\u001b[0m, in \u001b[0;36mexecute_notebook\u001b[1;34m(input_path, output_path, parameters, engine_name, request_save_on_cell_execute, prepare_only, kernel_name, language, progress_bar, log_output, stdout_file, stderr_file, start_timeout, report_mode, cwd, **engine_kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m         nb \u001b[38;5;241m=\u001b[39m papermill_engines\u001b[38;5;241m.\u001b[39mexecute_notebook_with_engine(\n\u001b[0;32m    117\u001b[0m             engine_name,\n\u001b[0;32m    118\u001b[0m             nb,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[0;32m    128\u001b[0m         )\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# Check for errors first (it saves on error before raising)\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m     \u001b[43mraise_for_execution_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# Write final output in case the engine didn't write it on cell completion.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m write_ipynb(nb, output_path)\n",
      "File \u001b[1;32mc:\\Users\\sangeetha\\anaconda3\\envs\\ndd\\Lib\\site-packages\\papermill\\execute.py:251\u001b[0m, in \u001b[0;36mraise_for_execution_errors\u001b[1;34m(nb, output_path)\u001b[0m\n\u001b[0;32m    248\u001b[0m nb\u001b[38;5;241m.\u001b[39mcells\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, error_msg_cell)\n\u001b[0;32m    250\u001b[0m write_ipynb(nb, output_path)\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[1;31mPapermillExecutionError\u001b[0m: \n---------------------------------------------------------------------------\nException encountered at \"In [4]\":\n---------------------------------------------------------------------------\nUnicodeDecodeError                        Traceback (most recent call last)\nCell In[4], line 1\n----> 1 df = pd.read_csv(input_csv_url)\n\nFile c:\\Users\\sangeetha\\anaconda3\\envs\\ndd\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-> 1026 return _read(filepath_or_buffer, kwds)\n\nFile c:\\Users\\sangeetha\\anaconda3\\envs\\ndd\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--> 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile c:\\Users\\sangeetha\\anaconda3\\envs\\ndd\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-> 1620 self._engine = self._make_engine(f, self.engine)\n\nFile c:\\Users\\sangeetha\\anaconda3\\envs\\ndd\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898, in TextFileReader._make_engine(self, f, engine)\n   1895     raise ValueError(msg)\n   1897 try:\n-> 1898     return mapping[engine](f, **self.options)\n   1899 except Exception:\n   1900     if self.handles is not None:\n\nFile c:\\Users\\sangeetha\\anaconda3\\envs\\ndd\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93, in CParserWrapper.__init__(self, src, **kwds)\n     90 if kwds[\"dtype_backend\"] == \"pyarrow\":\n     91     # Fail here loudly instead of in cython after reading\n     92     import_optional_dependency(\"pyarrow\")\n---> 93 self._reader = parsers.TextReader(src, **kwds)\n     95 self.unnamed_cols = self._reader.unnamed_cols\n     97 # error: Cannot determine type of 'names'\n\nFile parsers.pyx:574, in pandas._libs.parsers.TextReader.__cinit__()\n\nFile parsers.pyx:663, in pandas._libs.parsers.TextReader._get_header()\n\nFile parsers.pyx:874, in pandas._libs.parsers.TextReader._tokenize_rows()\n\nFile parsers.pyx:891, in pandas._libs.parsers.TextReader._check_tokenize_status()\n\nFile parsers.pyx:2053, in pandas._libs.parsers.raise_parser_error()\n\nFile <frozen codecs>:322, in decode(self, input, final)\n\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x96 in position 22: invalid start byte\n"
     ]
    }
   ],
   "source": [
    "params = dict(input_csv_url = \"https://uni-bonn.sciebo.de/s/W7BDPZefE53j7sy/download\")\n",
    "pm.execute_notebook(\n",
    "    'parameterization/notebook_1.ipynb',\n",
    "    'parameterization/output_notebook_run_3.ipynb',\n",
    "    parameters = params\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
